{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638af0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.63.6-py3-none-any.whl (249 kB)\n",
      "     -------------------------------------- 249.1/249.1 KB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sentencepiece in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (0.1.96)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     ---------------------------------------- 43.6/43.6 KB 2.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (1.22.3)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.8.1-py2.py3-none-any.whl (10.1 MB)\n",
      "     ---------------------------------------- 10.1/10.1 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.47.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: tensorboard in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (2.8.0)\n",
      "Requirement already satisfied: scipy in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (1.4.1)\n",
      "Requirement already satisfied: regex in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (2022.3.15)\n",
      "Requirement already satisfied: scikit-learn in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (0.21.2)\n",
      "Collecting wandb>=0.10.32\n",
      "  Downloading wandb-0.12.14-py2.py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (0.25.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
      "     -------------------------------------- 325.4/325.4 KB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tokenizers in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (0.11.6)\n",
      "Requirement already satisfied: requests in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (2.22.0)\n",
      "Requirement already satisfied: transformers>=4.6.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from simpletransformers) (4.18.0)\n",
      "Requirement already satisfied: colorama in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tqdm>=4.47.0->simpletransformers) (0.4.4)\n",
      "Requirement already satisfied: sacremoses in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from transformers>=4.6.0->simpletransformers) (0.0.35)\n",
      "Requirement already satisfied: filelock in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from transformers>=4.6.0->simpletransformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from transformers>=4.6.0->simpletransformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from transformers>=4.6.0->simpletransformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from transformers>=4.6.0->simpletransformers) (0.5.1)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.2/181.2 KB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (2.8.2)\n",
      "Requirement already satisfied: six>=1.13.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (3.20.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (7.1.2)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Using cached shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n",
      "     -------------------------------------- 144.9/144.9 KB 1.1 MB/s eta 0:00:00\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp38-cp38-win_amd64.whl (10 kB)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pathtools\n",
      "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: psutil>=5.0.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (5.9.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from requests->simpletransformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from requests->simpletransformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from requests->simpletransformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from requests->simpletransformers) (3.0.4)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-win_amd64.whl (555 kB)\n",
      "     -------------------------------------- 556.0/556.0 KB 1.5 MB/s eta 0:00:00\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "     -------------------------------------- 136.1/136.1 KB 1.6 MB/s eta 0:00:00\n",
      "Collecting pyarrow>=5.0.0\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-win_amd64.whl (16.1 MB)\n",
      "     ---------------------------------------- 16.1/16.1 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-win_amd64.whl (29 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "     -------------------------------------- 128.3/128.3 KB 1.9 MB/s eta 0:00:00\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from pandas->simpletransformers) (2019.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from scikit-learn->simpletransformers) (1.1.0)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.0.2-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from scikit-learn->simpletransformers) (3.1.0)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "     -------------------------------------- 111.5/111.5 KB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from streamlit->simpletransformers) (4.11.3)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cachetools>=4.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from streamlit->simpletransformers) (5.0.0)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "     -------------------------------------- 164.8/164.8 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tornado>=5.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from streamlit->simpletransformers) (6.1)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "     -------------------------------------- 812.8/812.8 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.7-py3-none-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.8/76.8 KB 2.1 MB/s eta 0:00:00\n",
      "Collecting toml\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: attrs in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from streamlit->simpletransformers) (21.4.0)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from streamlit->simpletransformers) (9.1.0)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (1.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (62.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (1.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (2.6.3)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (2.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from tensorboard->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.1.1)\n",
      "Requirement already satisfied: entrypoints in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.4)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.11.2-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.8/55.8 KB 2.9 MB/s eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "     ---------------------------------------- 63.1/63.1 KB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.6.0->simpletransformers) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from importlib-metadata>=1.4->streamlit->simpletransformers) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from packaging>=20.0->transformers>=4.6.0->simpletransformers) (3.0.8)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.1.1)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (6.12.1)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp38-cp38-win_amd64.whl (33 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (2.0.12)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (1.7.2)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-win_amd64.whl (38 kB)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n",
      "     -------------------------------------- 339.5/339.5 KB 1.2 MB/s eta 0:00:00\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from validators->streamlit->simpletransformers) (5.1.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (7.2.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.5)\n",
      "Requirement already satisfied: ipython>=7.23.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (8.2.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit->simpletransformers) (2.1.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (5.6.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.18.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: backcall in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.0.29)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.18.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.11.2)\n",
      "Requirement already satisfied: stack-data in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n",
      "Requirement already satisfied: pyzmq>=22.3 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (22.3.0)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.9.2)\n",
      "Requirement already satisfied: fastjsonschema in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.15.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (6.4.10)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.3)\n",
      "Requirement already satisfied: pywin32>=1.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (303)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.8.0)\n",
      "Requirement already satisfied: nbconvert>=5 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (6.4.5)\n",
      "Requirement already satisfied: argon2-cffi in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.13.3)\n",
      "Requirement already satisfied: wcwidth in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.5)\n",
      "Requirement already satisfied: executing in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.3)\n",
      "Requirement already satisfied: asttokens in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.11.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n",
      "Requirement already satisfied: bleach in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.0)\n",
      "Requirement already satisfied: testpath in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.13)\n",
      "Requirement already satisfied: defusedxml in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.0.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.3.2)\n",
      "Requirement already satisfied: webencodings in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n",
      "Requirement already satisfied: pycparser in d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.21)\n",
      "Building wheels for collected packages: seqeval, promise, blinker, pathtools\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=48e60d17c37de0252f487e74a42136e406b74f259e9b751905c4496d32d9f512\n",
      "  Stored in directory: c:\\users\\milan\\appdata\\local\\pip\\cache\\wheels\\ad\\5c\\ba\\05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=be96304a12057e2a8c2b764d218554d983e9c9c1ac6e53d0ea566fcbb7d2e246\n",
      "  Stored in directory: c:\\users\\milan\\appdata\\local\\pip\\cache\\wheels\\54\\aa\\01\\724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for blinker (setup.py): started\n",
      "  Building wheel for blinker (setup.py): finished with status 'done'\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=048f12b435540fa9cce59571469503724b2e9075778843333ca6c4537e0f3129\n",
      "  Stored in directory: c:\\users\\milan\\appdata\\local\\pip\\cache\\wheels\\b7\\a5\\68\\fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=df4f386d1bb913a71741c2b2240e2872005837759cc73134b2f3fdbd2e8dc87c\n",
      "  Stored in directory: c:\\users\\milan\\appdata\\local\\pip\\cache\\wheels\\4c\\8e\\7e\\72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built seqeval promise blinker pathtools\n",
      "Installing collected packages: pathtools, blinker, xxhash, watchdog, validators, tzdata, tqdm, toolz, toml, smmap, shortuuid, setproctitle, sentry-sdk, semver, pympler, pyarrow, promise, fsspec, frozenlist, docker-pycreds, dill, backports.zoneinfo, async-timeout, scikit-learn, responses, pytz-deprecation-shim, multiprocess, gitdb, aiosignal, tzlocal, seqeval, GitPython, altair, aiohttp, wandb, datasets, pydeck, streamlit, simpletransformers\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.21.2\n",
      "    Uninstalling scikit-learn-0.21.2:\n",
      "      Successfully uninstalled scikit-learn-0.21.2\n",
      "Successfully installed GitPython-3.1.27 aiohttp-3.8.1 aiosignal-1.2.0 altair-4.2.0 async-timeout-4.0.2 backports.zoneinfo-0.2.1 blinker-1.4 datasets-2.1.0 dill-0.3.4 docker-pycreds-0.4.0 frozenlist-1.3.0 fsspec-2022.3.0 gitdb-4.0.9 multiprocess-0.70.12.2 pathtools-0.1.2 promise-2.3 pyarrow-7.0.0 pydeck-0.7.1 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 responses-0.18.0 scikit-learn-1.0.2 semver-2.13.0 sentry-sdk-1.5.10 seqeval-1.2.2 setproctitle-1.2.3 shortuuid-1.0.8 simpletransformers-0.63.6 smmap-5.0.0 streamlit-1.8.1 toml-0.10.2 toolz-0.11.2 tqdm-4.64.0 tzdata-2022.1 tzlocal-4.2 validators-0.18.2 wandb-0.12.14 watchdog-2.1.7 xxhash-3.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deeppavlov 0.14.0 requires numpy==1.18.0, but you have numpy 1.22.3 which is incompatible.\n",
      "deeppavlov 0.14.0 requires scikit-learn==0.21.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "deeppavlov 0.14.0 requires tqdm==4.41.1, but you have tqdm 4.64.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3be9d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from simpletransformers.config.model_args import ModelArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2040abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\cryptography\\hazmat\\backends\\openssl\\x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTextRepresentation: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArgs(max_seq_length=156)\n",
    "model = RepresentationModel(\n",
    "        model_type=\"bert\",\n",
    "        model_name=\"bert-base-uncased\",\n",
    "        args=model_args,\n",
    "        use_cuda=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba2935fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Machine Learning and Deep Learning are part of AI\", \"Data Science will excel in future\"]\n",
    "word_vectors = model.encode_sentences(sentences, combine_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "695173be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11, 768)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fac5098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.23119886,  0.26005006, -0.2777042 , ..., -0.29340363,\n",
       "          0.80431867,  0.42281482],\n",
       "        [-0.31434646,  0.5668921 , -0.12599686, ..., -0.4730705 ,\n",
       "          0.9166614 , -0.55583346],\n",
       "        [-0.1050404 ,  0.41540074,  0.4367803 , ..., -0.49265668,\n",
       "          0.29159057, -0.5465346 ],\n",
       "        ...,\n",
       "        [-0.10692422,  0.14539418, -0.36244288, ..., -0.41278106,\n",
       "          0.49094933, -0.20987986],\n",
       "        [-0.5188851 , -0.65810025, -0.91081643, ...,  0.37581918,\n",
       "          0.8849107 , -0.17310207],\n",
       "        [ 0.50818694,  0.1289196 , -0.5035093 , ...,  0.15610753,\n",
       "         -0.5364386 , -0.5237989 ]],\n",
       "\n",
       "       [[-0.174151  ,  0.16519183,  0.07086699, ..., -0.2963491 ,\n",
       "          0.33841896, -0.11301601],\n",
       "        [-0.18326975, -0.01264533,  0.48765248, ..., -0.3803951 ,\n",
       "          0.07354411, -0.5296344 ],\n",
       "        [ 0.0318611 , -0.18739384,  1.1199814 , ..., -0.45969388,\n",
       "         -0.4631752 , -0.4947714 ],\n",
       "        ...,\n",
       "        [-0.00217915, -0.12765282,  0.28663254, ..., -0.13119319,\n",
       "          0.07172822, -0.2321362 ],\n",
       "        [ 0.08365107, -0.21041417,  0.14407925, ..., -0.03940061,\n",
       "         -0.02436963, -0.25633094],\n",
       "        [-0.01561609, -0.17489645,  0.1653591 , ..., -0.01372813,\n",
       "         -0.06601062, -0.2445723 ]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c8fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4c0eb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Way to drop the ball on customer service @1158...</td>\n",
       "      <td>@115820 I'm sorry we've let you down! Without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AmazonHelp 3 different people have given 3 di...</td>\n",
       "      <td>@115820 We'd like to take a further look into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@115823 I want my amazon payments account CLOS...</td>\n",
       "      <td>@115822 I am unable to affect your account via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115828 How about you guys figure out my Xbox ...</td>\n",
       "      <td>@115826 I'm sorry for the wait. You'll receive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AmazonHelp @115826 Yeah this is crazy we’re l...</td>\n",
       "      <td>@115827 Thanks for your patience. ^KM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131622</th>\n",
       "      <td>@AmazonHelp I sent you guys a DM regarding the...</td>\n",
       "      <td>@328597 We're unable to access customer accoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131623</th>\n",
       "      <td>This is happening in my area w/@115821 “Prime”...</td>\n",
       "      <td>@777901 I'm sorry for the delay, Brenda! We st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131624</th>\n",
       "      <td>@132994 @132995 @115850 got my #OnePlus5T at 8...</td>\n",
       "      <td>@823783 Woohoo! That's awesome! Hope you love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131625</th>\n",
       "      <td>@115850 @132994 No exchange available for #One...</td>\n",
       "      <td>@823802 The Exchange Offer is currently availa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131626</th>\n",
       "      <td>@115850  there should be bonus and gifts for r...</td>\n",
       "      <td>@823829 We do not have any such offer at this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     User  \\\n",
       "0       Way to drop the ball on customer service @1158...   \n",
       "1       @AmazonHelp 3 different people have given 3 di...   \n",
       "2       @115823 I want my amazon payments account CLOS...   \n",
       "3       @115828 How about you guys figure out my Xbox ...   \n",
       "4       @AmazonHelp @115826 Yeah this is crazy we’re l...   \n",
       "...                                                   ...   \n",
       "131622  @AmazonHelp I sent you guys a DM regarding the...   \n",
       "131623  This is happening in my area w/@115821 “Prime”...   \n",
       "131624  @132994 @132995 @115850 got my #OnePlus5T at 8...   \n",
       "131625  @115850 @132994 No exchange available for #One...   \n",
       "131626  @115850  there should be bonus and gifts for r...   \n",
       "\n",
       "                                                  Company  \n",
       "0       @115820 I'm sorry we've let you down! Without ...  \n",
       "1       @115820 We'd like to take a further look into ...  \n",
       "2       @115822 I am unable to affect your account via...  \n",
       "3       @115826 I'm sorry for the wait. You'll receive...  \n",
       "4                   @115827 Thanks for your patience. ^KM  \n",
       "...                                                   ...  \n",
       "131622  @328597 We're unable to access customer accoun...  \n",
       "131623  @777901 I'm sorry for the delay, Brenda! We st...  \n",
       "131624  @823783 Woohoo! That's awesome! Hope you love ...  \n",
       "131625  @823802 The Exchange Offer is currently availa...  \n",
       "131626  @823829 We do not have any such offer at this ...  \n",
       "\n",
       "[131248 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/amazon_data.csv\")\n",
    "df.dropna(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57ceadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for el in df['User']:\n",
    "    if(len(el) > max):\n",
    "        max = len(el)\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c71adbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"User\"] = df[\"User\"].str.pad(max, side ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a5ae648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['User'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0c1f764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5445fb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2625"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44794ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@AmazonHelp Kindly make some arrangements where deliveries are combined and delivered at a time.                                                                                                                                                                                                                                                                             '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = list(test_data['User'])\n",
    "user_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6357c489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\simpletransformers\\language_representation\\representation_model.py:208\u001b[0m, in \u001b[0;36mRepresentationModel.encode_sentences\u001b[1;34m(self, text_list, combine_strategy, batch_size)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 208\u001b[0m         token_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken_type_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m         token_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    215\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39mencoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    216\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mencoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    217\u001b[0m         )\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\simpletransformers\\language_representation\\transformer_models\\bert_model.py:24\u001b[0m, in \u001b[0;36mBertForTextRepresentation.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     18\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m ):\n\u001b[1;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    987\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    989\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    990\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    991\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    994\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    995\u001b[0m )\n\u001b[1;32m--> 996\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1009\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    576\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    578\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    583\u001b[0m     )\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    595\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    462\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    394\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    401\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 402\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:330\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    327\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32md:\\projects\\python projects\\pythonproject-3.8\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1818\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1816\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1818\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1820\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "word_vectors = model.encode_sentences(list(test_data['User']), combine_strategy=None, batch_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9ba12db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 83, 768)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11fd5c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.31712586,  0.03931233, -0.05333621, ..., -0.5418769 ,\n",
       "          0.34623292,  0.5413295 ],\n",
       "        [ 1.4477445 , -0.07055611,  0.19089608, ..., -0.3780279 ,\n",
       "          0.4610267 ,  0.10329035],\n",
       "        [ 0.5517399 ,  0.22782955,  0.24580523, ..., -0.29237118,\n",
       "          0.1689373 ,  0.1913368 ],\n",
       "        ...,\n",
       "        [ 0.55761856, -0.18209979,  0.3398738 , ..., -0.10797095,\n",
       "         -0.18947436, -0.17530203],\n",
       "        [ 0.3150739 , -0.4307106 ,  0.06201648, ...,  0.01619495,\n",
       "          0.01585684, -0.44130632],\n",
       "        [ 0.7558852 , -0.04972877,  0.37201157, ..., -0.05936575,\n",
       "          0.07613261,  0.02252985]],\n",
       "\n",
       "       [[ 0.1776245 ,  0.16967717,  0.03384627, ..., -0.33282232,\n",
       "          0.17628045,  0.30928847],\n",
       "        [ 0.64029634, -0.04087582,  0.54148424, ..., -0.51990235,\n",
       "         -0.02319512,  0.06260801],\n",
       "        [-0.01255745,  0.07867885,  0.43044472, ..., -0.23044866,\n",
       "         -0.29002774,  0.03746303],\n",
       "        ...,\n",
       "        [ 0.09297419, -0.18695316,  0.15403505, ..., -0.23027484,\n",
       "          0.0083773 ,  0.09301881],\n",
       "        [ 0.25735348, -0.33508578,  0.25207725, ..., -0.16759829,\n",
       "         -0.03288189,  0.05342831],\n",
       "        [ 0.08116172, -0.17344514,  0.13697544, ..., -0.09585254,\n",
       "          0.00649079,  0.12240177]],\n",
       "\n",
       "       [[-0.02978128,  0.02709069,  0.03299269, ..., -0.6652588 ,\n",
       "          0.5594168 ,  0.44582966],\n",
       "        [ 0.5043216 , -0.18879566,  0.8335428 , ..., -0.6126789 ,\n",
       "          0.6861954 ,  0.5636442 ],\n",
       "        [ 0.38735354, -0.34256706,  0.40576422, ..., -0.5777625 ,\n",
       "          0.16846153,  0.01661477],\n",
       "        ...,\n",
       "        [ 0.8609142 , -0.24949273,  0.20052099, ..., -0.2669333 ,\n",
       "          0.07648063, -0.77696383],\n",
       "        [ 0.6213809 , -0.23396811,  0.32973805, ..., -0.25359687,\n",
       "          0.02692961, -0.9101894 ],\n",
       "        [ 0.78386503, -0.3321366 ,  0.4665857 , ..., -0.34047252,\n",
       "          0.11083871, -0.69061136]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.09257316,  0.21386278, -0.0181095 , ..., -0.54632556,\n",
       "          0.48364094,  0.14016573],\n",
       "        [ 0.88649124,  0.1961529 ,  0.4072226 , ..., -0.7249534 ,\n",
       "          0.475764  ,  0.01747051],\n",
       "        [-0.16496058, -0.01607916,  0.8017243 , ..., -0.6778995 ,\n",
       "          0.3062253 ,  0.49217448],\n",
       "        ...,\n",
       "        [ 0.6154379 , -0.18553078,  0.03110072, ..., -0.22732806,\n",
       "          0.18292189, -1.0943325 ],\n",
       "        [ 0.4811472 , -0.43209812,  0.2858057 , ..., -0.20852765,\n",
       "          0.1328021 , -1.0619999 ],\n",
       "        [ 0.55467093, -0.33152407,  0.3679763 , ..., -0.30532762,\n",
       "          0.17394277, -1.0922803 ]],\n",
       "\n",
       "       [[ 0.33074805,  0.25859928,  0.23009472, ..., -0.3324896 ,\n",
       "          0.4337406 ,  0.11902388],\n",
       "        [ 1.395077  ,  0.21615234, -0.08624604, ..., -0.40515456,\n",
       "          0.9190941 ,  0.17023116],\n",
       "        [ 0.45605364,  0.19631225,  0.4487968 , ..., -0.25653523,\n",
       "          0.34503144, -0.24444725],\n",
       "        ...,\n",
       "        [ 0.905023  ,  0.26636797,  0.09098766, ..., -0.22717606,\n",
       "          0.0628935 , -0.46399233],\n",
       "        [ 0.8477848 ,  0.21530175,  0.12034503, ..., -0.26813236,\n",
       "          0.04887801, -0.4841532 ],\n",
       "        [ 1.187353  ,  0.12910447,  0.22905359, ..., -0.33507746,\n",
       "         -0.0071137 , -0.32487863]],\n",
       "\n",
       "       [[ 0.32402283,  0.09594201,  0.16976537, ..., -0.7377176 ,\n",
       "          0.5071716 ,  0.45473582],\n",
       "        [ 1.3111506 ,  0.4597847 ,  0.3306536 , ..., -0.24622613,\n",
       "          0.39385098, -0.15337636],\n",
       "        [ 0.40798438,  0.1936881 ,  0.2751767 , ..., -0.397311  ,\n",
       "          0.03455761, -0.04406612],\n",
       "        ...,\n",
       "        [ 0.17218982, -0.23271194,  0.31728506, ..., -0.03312685,\n",
       "          0.05067289,  0.16998567],\n",
       "        [ 0.21114507, -0.22124052,  0.26430452, ..., -0.08834629,\n",
       "          0.06393074,  0.1811722 ],\n",
       "        [ 0.45827746, -0.31424376,  0.4032459 , ..., -0.06988987,\n",
       "         -0.15250657,  0.00690339]]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a1b769a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 768)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbb88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
